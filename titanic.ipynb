{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# SÃ£o Paulo 07 de Agosto 2019\n## Competition Description\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Arquivos: {train.csv, test.csv, gender_submission.csv}"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Instalando xgboot\n!pip install --upgrade pip\n!pip install xgboost",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: pip in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (19.2.1)\nRequirement already satisfied: xgboost in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (0.90)\nRequirement already satisfied: numpy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from xgboost) (1.16.4)\nRequirement already satisfied: scipy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from xgboost) (1.1.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Realizando os imports\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np",
      "execution_count": 93,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the data\ntrain_df = pd.read_csv('data/train.csv', header=0)\ntest_df = pd.read_csv('data/test.csv', header=0)\n",
      "execution_count": 94,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We'll impute missing values using the median for numeric columns and the most\n# common value for string columns.\n# This is based on some nice code by 'sveitser' at http://stackoverflow.com/a/25562948\nfrom sklearn.base import TransformerMixin",
      "execution_count": 95,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n\nfeature_columns_to_use = ['Pclass','Sex','Age','Fare','Parch']\nnonnumeric_columns = ['Sex']\n",
      "execution_count": 96,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Join the features from train and test together before imputing missing values,\n# in case their distribution is slightly different\nbig_X = train_df[feature_columns_to_use].append(test_df[feature_columns_to_use])\nbig_X_imputed = DataFrameImputer().fit_transform(big_X)\n",
      "execution_count": 97,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# XGBoost doesn't (yet) handle categorical features automatically, so we need to change\n# them to columns of integer values.\n# See http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing for more\n# details and options\nle = LabelEncoder()\nfor feature in nonnumeric_columns:\n    big_X_imputed[feature] = le.fit_transform(big_X_imputed[feature])\n",
      "execution_count": 98,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Prepare the inputs for the model\ntrain_X = big_X_imputed[0:train_df.shape[0]].as_matrix()\ntest_X = big_X_imputed[train_df.shape[0]::].as_matrix()\ntrain_y = train_df['Survived']\n\n",
      "execution_count": 99,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# You can experiment with many other options here, using the same .fit() and .predict()\n# methods; see http://scikit-learn.org\n# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\ngbm = xgb.XGBClassifier(max_depth=3, n_estimators=333, learning_rate=0.0001).fit(train_X, train_y)\npredictions = gbm.predict(test_X)\n",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Kaggle needs the submission to have a certain format;\n# see https://www.kaggle.com/c/titanic-gettingStarted/download/gendermodel.csv\n# for an example of what it's supposed to look like.\nsubmission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n                            'Survived': predictions })\nsubmission.to_csv(\"submission.csv\", index=False)",
      "execution_count": 101,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install kaggle",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: kaggle in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (1.5.5)\nRequirement already satisfied: python-dateutil in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (2.8.0)\nRequirement already satisfied: python-slugify in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (3.0.3)\nRequirement already satisfied: tqdm in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (4.32.2)\nRequirement already satisfied: six>=1.10 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (1.11.0)\nRequirement already satisfied: requests in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (2.14.2)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (1.24.3)\nRequirement already satisfied: certifi in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from kaggle) (2019.6.16)\nRequirement already satisfied: text-unidecode==1.2 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from python-slugify->kaggle) (1.2)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
    {
      "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
